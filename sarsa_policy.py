import numpy as np

class SARSA_Policy:
    def __init__(self, num_actions):
        self.num_actions = num_actions
        self.q_values = np.zeros(num_actions)

    def select_action(self, state):
        # Implement your SARSA policy here
        # You can use the current state and Q-values to determine the next action
        # Feel free to use exploration strategies such as epsilon-greedy

        # For example, a simple epsilon-greedy strategy:
        epsilon = 0.1
        if np.random.rand() < epsilon:
            # Explore: Choose a random action
            return np.random.choice(["left", "right", "none"])
        else:
            # Exploit: Choose the action with the highest Q-value
            return ["left", "right", "none"][np.argmax(self.q_values)]

    def update_q_values(self, state, action, reward, next_state, next_action, alpha=0.1, gamma=0.9):
        # SARSA update rule
        target = reward + gamma * self.q_values[next_action]
        error = target - self.q_values[action]
        self.q_values[action] += alpha * error
